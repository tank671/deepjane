{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic text generation in the style of Jane Austen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import pkg_resources\n",
    "from pathlib import Path\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the fastai library, and training on Jane Austen's collected works from the Gutenberg project.  I removed titles and chapter headings, and arranged the text so that each paragraph occupied one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.37'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkg_resources.get_distribution(\"fastai\").version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app\t\t  Dockerfile  now.json\t\ttexts.csv  todo\r\n",
      "austen_gen.ipynb  notes       requirements.txt\ttexts.txt  zeit.tgz\r\n"
     ]
    }
   ],
   "source": [
    "path = Path('.')\n",
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the last century; and there, if every other leaf were powerless, he could read his own history with an interest which never failed.  This was the page at which the favourite volume always opened:\r",
      "\r\n",
      "            \"ELLIOT OF KELLYNCH HALL.\r",
      "\r\n",
      " \"Walter Elliot, born March 1, 1760, married, July 15, 1784, Elizabeth, daughter of James Stevenson, Esq. of South Park, in the county of Gloucester, by which lady (who died 1800) he has issue Elizabeth, born June 1, 1785; Anne, born August 9, 1787; a still-born son, November 5, 1789; Mary, born November 20, 1791.\"\r",
      "\r\n",
      " Precisely such had the paragraph originally stood from the printer's hands; but Sir Walter had improved it by adding, for the information of himself and his family, these words, after the date of Mary's birth-- \"Married, December 16, 1810, Charles, son and heir of Charles Musgrove, Esq. of Uppercross, in the county of Somerset,\" and by inserting most accurately the day of the month on which he had lost his wife.\r",
      "\r\n",
      " Then followed the history and rise of the ancient and respectable family, in the usual terms; how it had been first settled in Cheshire; how mentioned in Dugdale, serving the office of high sheriff, representing a borough in three successive parliaments, exertions of loyalty, and dignity of baronet, in the first year of Charles II, with all the Marys and Elizabeths they had married; forming altogether two handsome duodecimo pages, and concluding with the arms and motto:--\"Principal seat, Kellynch Hall, in the county of Somerset,\" and Sir Walter's handwriting again in this finale:--\r",
      "\r\n",
      " \"Heir presumptive, William Walter Elliot, Esq., great grandson of the second Sir Walter.\"\r",
      "\r\n",
      " Vanity was the beginning and the end of Sir Walter Elliot's character; vanity of person and of situation.  He had been remarkably handsome in his youth; and, at fifty-four, was still a very fine man.  Few women could think more of their personal appearance than he did, nor could the valet of any new made lord be more delighted with the place he held in society.  He considered the blessing of beauty as inferior only to the blessing of a baronetcy; and the Sir Walter Elliot, who united these gifts, was the constant object of his warmest respect and devotion.\r",
      "\r\n",
      " His good looks and his rank had one fair claim on his attachment; since to them he must have owed a wife of very superior character to any thing deserved by his own.  Lady Elliot had been an excellent woman, sensible and amiable; whose judgement and conduct, if they might be pardoned the youthful infatuation which made her Lady Elliot, had never required indulgence afterwards.--She had humoured, or softened, or concealed his failings, and promoted his real respectability for seventeen years; and though not the very happiest being in the world herself, had found enough in her duties, her friends, and her children, to attach her to life, and make it no matter of indifference to her when she was called on to quit them.--Three girls, the two eldest sixteen and fourteen, was an awful legacy for a mother to bequeath, an awful charge rather, to confide to the authority and guidance of a conceited, silly father.  She had, however, one very intimate friend, a sensible, deserving woman, who had been brought, by strong attachment to herself, to settle close by her, in the village of Kellynch; and on her kindness and advice, Lady Elliot mainly relied for the best help and maintenance of the good principles and instruction which she had been anxiously giving her daughters.\r",
      "\r\n",
      " This friend, and Sir Walter, did not marry, whatever might have been anticipated on that head by their acquaintance.  Thirteen years had passed away since Lady Elliot's death, and they were still near neighbours and intimate friends, and one remained a widower, the other a widow.\r",
      "\r\n",
      " That Lady Russell, of steady age and character, and extremely well provided for, should have no thought of a second marriage, needs no apology to the public, which is rather apt to be unreasonably discontented when a woman does marry again, than when she does not; but Sir Walter's continuing in singleness requires explanation.  Be it known then, that Sir Walter, like a good father, (having met with one or two private disappointments in very unreasonable applications), prided himself on remaining single for his dear daughters' sake.  For one daughter, his eldest, he would really have given up any thing, which he had not been very much tempted to do.  Elizabeth had succeeded, at sixteen, to all that was possible, of her mother's rights and consequence; and being very handsome, and very like himself, her influence had always been great, and they had gone on together most happily.  His two other children were of very inferior value.  Mary had acquired a little artificial importance, by becoming Mrs Charles Musgrove; but Anne, with an elegance of mind and sweetness of character, which must have placed her high with any people of real understanding, was nobody with either father or sister; her word had no weight, her convenience was always to give way--she was only Anne.\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11788 texts.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l texts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'texts.txt', delimiter=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Walter Elliot, of Kellynch Hall, in Somers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ELLIOT OF KELLYNCH HALL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Walter Elliot, born March 1, 1760, married, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precisely such had the paragraph originally s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Then followed the history and rise of the anc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Sir Walter Elliot, of Kellynch Hall, in Somers...\n",
       "1                          \"ELLIOT OF KELLYNCH HALL.\n",
       "2   \"Walter Elliot, born March 1, 1760, married, ...\n",
       "3   Precisely such had the paragraph originally s...\n",
       "4   Then followed the history and rise of the anc..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Walter Elliot, of Kellynch Hall, in Somers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ELLIOT OF KELLYNCH HALL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Walter Elliot, born March 1, 1760, married, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precisely such had the paragraph originally s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Then followed the history and rise of the anc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Heir presumptive, William Walter Elliot, Esq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vanity was the beginning and the end of Sir W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>His good looks and his rank had one fair clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This friend, and Sir Walter, did not marry, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>That Lady Russell, of steady age and characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>To Lady Russell, indeed, she was a most dear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A few years before, Anne Elliot had been a ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It sometimes happens that a woman is handsome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Elizabeth did not quite equal her father in p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>She had had a disappointment, moreover, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>She had, while a very young girl, as soon as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>He was at that time a very young man, just en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sir Walter has resented it.  As the head of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This very awkward history of Mr Elliot was st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Such were Elizabeth Elliot's sentiments and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>But now, another occupation and solicitude of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>There was only a small part of his estate tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Their two confidential friends, Mr Shepherd, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mr Shepherd, a civil, cautious lawyer, who, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lady Russell was most anxiously zealous on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>They must retrench; that did not admit of a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"If we can persuade your father to all this,\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>This was the principle on which Anne wanted h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>How Anne's more rigid requisitions might have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Quit Kellynch Hall.\"  The hint was immediate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10652</th>\n",
       "      <td>This paragraph was of some importance to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>\"A letter of proper submission!\" repeated he;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>\"You may certainly ask to be forgiven,\" said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>He agreed that he might.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10656</th>\n",
       "      <td>\"And when she has forgiven you, perhaps a lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>He had nothing to urge against it, but still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>After a visit on Colonel Brandon's side of on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>After a proper resistance on the part of Mrs....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>Her family had of late been exceedingly fluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>In spite of his being allowed once more to li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>What she would engage to do towards augmentin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>It was as much, however, as was desired, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>With an income quite sufficient to their want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>The first month after their marriage was spen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10666</th>\n",
       "      <td>They were visited on their first settling by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10667</th>\n",
       "      <td>\"I will not say that I am disappointed, my de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10668</th>\n",
       "      <td>But though Mrs. Ferrars _did_ come to see the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10669</th>\n",
       "      <td>[Illustration: _Everything in such respectabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10670</th>\n",
       "      <td>The whole of Lucy's behaviour in the affair, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10671</th>\n",
       "      <td>What Edward had done to forfeit the right of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>Elinor's marriage divided her as little from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>With such a confederacy against her--with a k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>Marianne Dashwood was born to an extraordinar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>But so it was. Instead of falling a sacrifice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>Colonel Brandon was now as happy, as all thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Willoughby could not hear of her marriage wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>For Marianne, however, in spite of his incivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>Mrs. Dashwood was prudent enough to remain at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>Between Barton and Delaford, there was that c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>THE END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      Sir Walter Elliot, of Kellynch Hall, in Somers...\n",
       "1                              \"ELLIOT OF KELLYNCH HALL.\n",
       "2       \"Walter Elliot, born March 1, 1760, married, ...\n",
       "3       Precisely such had the paragraph originally s...\n",
       "4       Then followed the history and rise of the anc...\n",
       "5       \"Heir presumptive, William Walter Elliot, Esq...\n",
       "6       Vanity was the beginning and the end of Sir W...\n",
       "7       His good looks and his rank had one fair clai...\n",
       "8       This friend, and Sir Walter, did not marry, w...\n",
       "9       That Lady Russell, of steady age and characte...\n",
       "10      To Lady Russell, indeed, she was a most dear ...\n",
       "11      A few years before, Anne Elliot had been a ve...\n",
       "12      It sometimes happens that a woman is handsome...\n",
       "13      Elizabeth did not quite equal her father in p...\n",
       "14      She had had a disappointment, moreover, which...\n",
       "15      She had, while a very young girl, as soon as ...\n",
       "16      He was at that time a very young man, just en...\n",
       "17      Sir Walter has resented it.  As the head of t...\n",
       "18      This very awkward history of Mr Elliot was st...\n",
       "19      Such were Elizabeth Elliot's sentiments and s...\n",
       "20      But now, another occupation and solicitude of...\n",
       "21      There was only a small part of his estate tha...\n",
       "22      Their two confidential friends, Mr Shepherd, ...\n",
       "23      Mr Shepherd, a civil, cautious lawyer, who, w...\n",
       "24      Lady Russell was most anxiously zealous on th...\n",
       "25      They must retrench; that did not admit of a d...\n",
       "26      \"If we can persuade your father to all this,\"...\n",
       "27      This was the principle on which Anne wanted h...\n",
       "28      How Anne's more rigid requisitions might have...\n",
       "29      \"Quit Kellynch Hall.\"  The hint was immediate...\n",
       "...                                                  ...\n",
       "10652   This paragraph was of some importance to the ...\n",
       "10653   \"A letter of proper submission!\" repeated he;...\n",
       "10654   \"You may certainly ask to be forgiven,\" said ...\n",
       "10655                           He agreed that he might.\n",
       "10656   \"And when she has forgiven you, perhaps a lit...\n",
       "10657   He had nothing to urge against it, but still ...\n",
       "10658   After a visit on Colonel Brandon's side of on...\n",
       "10659   After a proper resistance on the part of Mrs....\n",
       "10660   Her family had of late been exceedingly fluct...\n",
       "10661   In spite of his being allowed once more to li...\n",
       "10662   What she would engage to do towards augmentin...\n",
       "10663   It was as much, however, as was desired, and ...\n",
       "10664   With an income quite sufficient to their want...\n",
       "10665   The first month after their marriage was spen...\n",
       "10666   They were visited on their first settling by ...\n",
       "10667   \"I will not say that I am disappointed, my de...\n",
       "10668   But though Mrs. Ferrars _did_ come to see the...\n",
       "10669   [Illustration: _Everything in such respectabl...\n",
       "10670   The whole of Lucy's behaviour in the affair, ...\n",
       "10671   What Edward had done to forfeit the right of ...\n",
       "10672   Elinor's marriage divided her as little from ...\n",
       "10673   With such a confederacy against her--with a k...\n",
       "10674   Marianne Dashwood was born to an extraordinar...\n",
       "10675   But so it was. Instead of falling a sacrifice...\n",
       "10676   Colonel Brandon was now as happy, as all thos...\n",
       "10677   Willoughby could not hear of her marriage wit...\n",
       "10678   For Marianne, however, in spite of his incivi...\n",
       "10679   Mrs. Dashwood was prudent enough to remain at...\n",
       "10680   Between Barton and Delaford, there was that c...\n",
       "10681                                            THE END\n",
       "\n",
       "[10682 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Walter Elliot, of Kellynch Hall, in Somers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ELLIOT OF KELLYNCH HALL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Walter Elliot, born March 1, 1760, married, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precisely such had the paragraph originally s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Then followed the history and rise of the anc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Sir Walter Elliot, of Kellynch Hall, in Somers...\n",
       "1                          \"ELLIOT OF KELLYNCH HALL.\n",
       "2   \"Walter Elliot, born March 1, 1760, married, ...\n",
       "3   Precisely such had the paragraph originally s...\n",
       "4   Then followed the history and rise of the anc..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" So far all was perfectly right; but Lady Russell was almost startled by the wrong of one part of the Kellynch Hall plan, when it burst on her, which was, Mrs Clay's being engaged to go to Bath with Sir Walter and Elizabeth, as a most important and valuable assistant to the latter in all the business before her.  Lady Russell was extremely sorry that such a measure should have been resorted to at all, wondered, grieved, and feared; and the affront it contained to Anne, in Mrs Clay's being of so much use, while Anne could be of none, was a very sore aggravation.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size\n",
    "bs = 48\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_lm = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "           .random_split_by_pct(0.1)\n",
    "           .label_for_lm()\n",
    "           .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
       "    <th>idx</th>\n",
       "    <th>text</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>xxbos \" xxmaj edward 's love for me , \" said xxmaj lucy , \" has been pretty well put to the test , by our long , very long absence since we were first engaged , and it has stood the trial so well , that i should be unpardonable to doubt it now . i can safely say that he has never gave me one moment 's alarm</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>understanding between the xxmaj colonel and xxmaj miss xxmaj dashwood seemed rather to declare that the honours of the xxunk - tree , the xxunk , and the yew xxunk , would all be made over to _ her _ ; and xxmaj mrs. xxmaj jennings had , for some time ceased to think at all of xxmaj mrs. xxmaj ferrars . xxbos xxmaj this was a sad xxunk of</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>three thousand pounds , again was she forced to hesitate . xxmaj she put down the letter , xxunk every circumstance with what she meant to be impartiality -- xxunk on the probability of each statement -- but with little success . xxmaj on both sides it was only assertion . xxmaj again she read on ; but every line proved more clearly that the affair , which she had</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>knightley are shut up together in deep consultation .-- xxmaj mr . xxup e. is xxmaj knightley 's right hand . \" xxbos \" xxmaj oh ! he must and shall come back , \" cried xxmaj sir xxmaj john . \" xxmaj if he is not here by the end of the week , i shall go after him . \" xxbos xxmaj no one who had ever seen</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>despise , \" said he . \" xxmaj if he wants our society , let him seek it . xxmaj he knows where we live . i will not spend my hours in running after my neighbours every time they go away and come back again . \" xxbos \" xxmaj who ? why yourselves , and the xxmaj careys , and xxmaj xxunk to be sure . xxmaj what</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "austen_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_lm.save('austen_lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen_lm = TextLMDataBunch.load(path, 'austen_lm', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,  14,   4,  12,   4, 123,  28,  78, 225,  20,  51,   4, 418,  37,\n",
       "          8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(austen_lm.train_dl))\n",
    "example = x[:15, :15].cpu()\n",
    "example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>\"</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>and</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>fanny</td>\n",
       "      <td>had</td>\n",
       "      <td>much</td>\n",
       "      <td>rather</td>\n",
       "      <td>it</td>\n",
       "      <td>were</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>william</td>\n",
       "      <td>'s</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not</td>\n",
       "      <td>believe</td>\n",
       "      <td>it</td>\n",
       "      <td>of</td>\n",
       "      <td>you</td>\n",
       "      <td>.--</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>all</td>\n",
       "      <td>idle</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>may</td>\n",
       "      <td>be</td>\n",
       "      <td>as</td>\n",
       "      <td>comfortable</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>he</td>\n",
       "      <td>seemed</td>\n",
       "      <td>to</td>\n",
       "      <td>have</td>\n",
       "      <td>no</td>\n",
       "      <td>idea</td>\n",
       "      <td>of</td>\n",
       "      <td>shrinking</td>\n",
       "      <td>from</td>\n",
       "      <td>it</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>set</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>musgrove</td>\n",
       "      <td>'s</td>\n",
       "      <td>civility</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>she</td>\n",
       "      <td>was</td>\n",
       "      <td>all</td>\n",
       "      <td>but</td>\n",
       "      <td>calling</td>\n",
       "      <td>there</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>agony</td>\n",
       "      <td>was</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>introduce</td>\n",
       "      <td>themselves</td>\n",
       "      <td>properly</td>\n",
       "      <td>.</td>\n",
       "      <td>xxbos</td>\n",
       "      <td>\"</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>may</td>\n",
       "      <td>i</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wonder</td>\n",
       "      <td>what</td>\n",
       "      <td>she</td>\n",
       "      <td>thinks</td>\n",
       "      <td>of</td>\n",
       "      <td>my</td>\n",
       "      <td>father</td>\n",
       "      <td>!</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>she</td>\n",
       "      <td>must</td>\n",
       "      <td>admire</td>\n",
       "      <td>him</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>her</td>\n",
       "      <td>own</td>\n",
       "      <td>,</td>\n",
       "      <td>a</td>\n",
       "      <td>gentleman</td>\n",
       "      <td>of</td>\n",
       "      <td>consequence</td>\n",
       "      <td>and</td>\n",
       "      <td>property</td>\n",
       "      <td>in</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>devonshire</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>i</td>\n",
       "      <td>remember</td>\n",
       "      <td>saying</td>\n",
       "      <td>to</td>\n",
       "      <td>myself</td>\n",
       "      <td>,</td>\n",
       "      <td>'</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>even</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>emma</td>\n",
       "      <td>,</td>\n",
       "      <td>with</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>therefore</td>\n",
       "      <td>,</td>\n",
       "      <td>on</td>\n",
       "      <td>my</td>\n",
       "      <td>account</td>\n",
       "      <td>,</td>\n",
       "      <td>have</td>\n",
       "      <td>you</td>\n",
       "      <td>xxunk</td>\n",
       "      <td>one</td>\n",
       "      <td>moment</td>\n",
       "      <td>of</td>\n",
       "      <td>your</td>\n",
       "      <td>precious</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>its</td>\n",
       "      <td>being</td>\n",
       "      <td>a</td>\n",
       "      <td>reciprocal</td>\n",
       "      <td>enjoyment</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>it</td>\n",
       "      <td>suggested</td>\n",
       "      <td>no</td>\n",
       "      <td>other</td>\n",
       "      <td>surprise</td>\n",
       "      <td>than</td>\n",
       "      <td>that</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>gentleman</td>\n",
       "      <td>'s</td>\n",
       "      <td>education</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>my</td>\n",
       "      <td>father</td>\n",
       "      <td>was</td>\n",
       "      <td>not</td>\n",
       "      <td>only</td>\n",
       "      <td>fond</td>\n",
       "      <td>of</td>\n",
       "      <td>this</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>are</td>\n",
       "      <td>,</td>\n",
       "      <td>to</td>\n",
       "      <td>whom</td>\n",
       "      <td>i</td>\n",
       "      <td>am</td>\n",
       "      <td>indebted</td>\n",
       "      <td>for</td>\n",
       "      <td>such</td>\n",
       "      <td>kind</td>\n",
       "      <td>intentions</td>\n",
       "      <td>,</td>\n",
       "      <td>could</td>\n",
       "      <td>see</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>that</td>\n",
       "      <td>her</td>\n",
       "      <td>friend</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>mrs</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>clay</td>\n",
       "      <td>was</td>\n",
       "      <td>encouraging</td>\n",
       "      <td>the</td>\n",
       "      <td>idea</td>\n",
       "      <td>,</td>\n",
       "      <td>seemed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>;</td>\n",
       "      <td>but</td>\n",
       "      <td>that</td>\n",
       "      <td>matters</td>\n",
       "      <td>should</td>\n",
       "      <td>be</td>\n",
       "      <td>brought</td>\n",
       "      <td>so</td>\n",
       "      <td>forward</td>\n",
       "      <td>between</td>\n",
       "      <td>them</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>nobody</td>\n",
       "      <td>suspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>must</td>\n",
       "      <td>be</td>\n",
       "      <td>the</td>\n",
       "      <td>best</td>\n",
       "      <td>judge</td>\n",
       "      <td>of</td>\n",
       "      <td>his</td>\n",
       "      <td>own</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>as</td>\n",
       "      <td>he</td>\n",
       "      <td>did</td>\n",
       "      <td>assure</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2           3          4          5   \\\n",
       "0       xxbos          \"     xxmaj         and      xxmaj      fanny   \n",
       "1         not    believe        it          of        you        .--   \n",
       "2           ,         he    seemed          to       have         no   \n",
       "3          mr      xxmaj  musgrove          's   civility          ,   \n",
       "4         the      agony       was         how         to  introduce   \n",
       "5      wonder       what       she      thinks         of         my   \n",
       "6         her        own         ,           a  gentleman         of   \n",
       "7           .          i  remember      saying         to     myself   \n",
       "8   therefore          ,        on          my    account          ,   \n",
       "9         its      being         a  reciprocal  enjoyment          .   \n",
       "10          a  gentleman        's   education          .      xxmaj   \n",
       "11        are          ,        to        whom          i         am   \n",
       "12          ,        and      that         her     friend      xxmaj   \n",
       "13          ;        but      that     matters     should         be   \n",
       "14       must         be       the        best      judge         of   \n",
       "\n",
       "             6         7          8        9            10          11  \\\n",
       "0           had      much     rather       it         were       xxmaj   \n",
       "1         xxmaj       all       idle    xxunk          may          be   \n",
       "2          idea        of  shrinking     from           it           ,   \n",
       "3           and       she        was      all          but     calling   \n",
       "4    themselves  properly          .    xxbos            \"       xxmaj   \n",
       "5        father         !      xxmaj      she         must      admire   \n",
       "6   consequence       and   property       in        xxmaj  devonshire   \n",
       "7             ,         '      xxmaj     even        xxmaj        emma   \n",
       "8          have       you      xxunk      one       moment          of   \n",
       "9         xxmaj        it  suggested       no        other    surprise   \n",
       "10           my    father        was      not         only        fond   \n",
       "11     indebted       for       such     kind   intentions           ,   \n",
       "12          mrs     xxmaj       clay      was  encouraging         the   \n",
       "13      brought        so    forward  between         them           ,   \n",
       "14          his       own          ,      and           as          he   \n",
       "\n",
       "         12           13       14  \n",
       "0   william           's        ,  \n",
       "1        as  comfortable       on  \n",
       "2       and          set  forward  \n",
       "3     there           in      the  \n",
       "4       may            i     hope  \n",
       "5       him           as        a  \n",
       "6         .        xxmaj      the  \n",
       "7         ,         with      all  \n",
       "8      your     precious     time  \n",
       "9      than         that    xxmaj  \n",
       "10       of         this    young  \n",
       "11    could          see      the  \n",
       "12     idea            ,   seemed  \n",
       "13      and       nobody  suspect  \n",
       "14      did       assure      her  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showtexts = pd.DataFrame([austen_lm.train_ds.vocab.textify(l).split(' ') for l in example])\n",
    "showtexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " ',',\n",
       " '.',\n",
       " 'the',\n",
       " 'to',\n",
       " 'and',\n",
       " 'of',\n",
       " '\"']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austen_lm.vocab.itos[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(austen_lm, pretrained_model=URLs.WT103_1, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNX5+PHPk4SEEEICJGELJOyrEiAgixuIS4Vi7VcRKoraqtWqqFW/8m1/rbV7rdVWrRapu4IV3K0LyqaYAGHftyRAwpIFCCEJWZ/fHzNoDFmGMHcmkzzv12teztx77r3PcUKenHPuPUdUFWOMMcbbgvwdgDHGmObJEowxxhhHWIIxxhjjCEswxhhjHGEJxhhjjCMswRhjjHGEJRhjjDGOsARjjDHGEZZgjDHGOCLE3wF4S0xMjCYmJvo7DGOMCShr1qzJU9VYJ87teIIRkWAgDchW1ck19j0BjHd/bAPEqWq0e99fgEm4WlmLgFlaz7w2iYmJpKWlOVADY4xpvkRkr1Pn9kULZhawDWhXc4eq3nfqvYjcDQxzvx8LjAPOde/+CrgIWOpwrMYYY7zE0TEYEYnH1QqZ60Hx6cA893sFWgOhQBjQCjjsRIzGGGOc4fQg/5PAQ0BVfYVEJAHoCSwGUNUUYAlw0P36VFW3ORuqMcYYb3IswYjIZCBHVdd4UHwasEBVK93H9gEGAvFAN2CCiFxYyzVuE5E0EUnLzc31YvTGGGPOlpMtmHHAFBHJBObjShKv1VF2Gt92jwFcDaSq6glVPQF8DIyueZCqzlHVZFVNjo115CYIY4wxjeRYglHV2aoar6qJuBLIYlWdUbOciPQH2gMp1TbvAy4SkRARaYVrgN+6yIwxJoD4/EFLEXlURKZU2zQdmF/jFuQFwB5gE7AB2KCqH/gwTGOMMWdJmsuSycnJyWrPwTTeseIyPtx4kP8ZHk94aLC/wzHG+IiIrFHVZCfO3Wye5DeNt+3gcW57NY39R0pI2ZPPU9OHERQk/g7rjBWXVfDJ5kMEBwmDu0bRMyaC4ACshzHNhSWYFu6/mw7y8/9sILJ1CDeMTuDV1L30iWvLfZf283doHtudU8hrqftYuCaLwtKKb7a3CQ1mUJd29O3Ulvj2bejeoQ3d24fTv3MkbULtR98Yp9m/shYgt7CUvy3awdd78ukZE0H/zpEM6BzJjkMneG7ZHob3iOa5GSOIjQzjZHklf/9iF33i2vL9oV39HXq9Vqbn84/Fu1ixO5/Q4CCuPKcz149OILJ1CJuzj7M5u4DN2QV8tuUw+UVl3xwX0zaUx64ZyvgBcX6M3pjmz8ZgmrHSikpeWpHJU4t3c7K8kov6xZJ9rIQ9uScor3R979NGduc3Vw0mLCT4m2NumLuKDVnH+M/tYxjaPdqfVajV2n1H+dtnO/lqdx5xkWHcNC6R65K707FtWJ3HFJVWkHW0hIy8Ip78fCfbDxVy45gE/u/KgbRuZWNOpuVycgzGEkwztTI9n4cWbmRvfjGXDIjjF5MG0iu2LQDllVVk5BVRXFbJ0PgoRL47TpF/opSrnllBWUUVc25MJslPSWZzdgGz5q+jokpp17oV7cJDKK9QVmUeoUNEKHde3JsZoxPOOEGcLK/ksU938O+vMugT15a7J/Qh62gJ2w8VsuPQcbKOllDl/nehCuGhwVwyoBNTkroyrndHQoJdN18eKSojZU8+G7OPMeO8BLp3aOP1/wfGOM0SjAcswXxrzd6jzJi7ks5RrfnNlMFc2O/MH0LdcaiQ6+emkneijEsGxHHfpf0Y0i3KgWhrV15ZxVVPryCn8CTj+sRwvKScgpJySsqrmHxuF24am0hE2Nn18H65K5ef/2cDOYWlAMS3D2dA50h6dIggJFgQAHF1MS7aepjCkxV0jAjl/L4x7Dx8gm0Hj39zrj5xbXn7zrG0a93qrGIyxtcswXjAEozLjkOFTP1XCu3btOKtn44lNrLubqOGnCit4OWvM5mzPJ2CknIuG9SJR6YMpmt0uBcjrt1zy/bwp4+389yM4VwxpItj1zl+spz03CJ6x0YQWU9yKK2oZOmOXN7fcIDUPfn07xzJuD4xjOndkeLSSm56cRVj+8Twwszkb1o4xgQCSzAesAQD+/KLuea5rxGBBT8d67Uum+Mny3nxq0zmLN9D9w5tWHjH2LNuPdRnb34Rlz2xnIv6xTLnRkd+7r1u/qp9PPz2Jm4am8gjUwb7OxxjPGbPwZgG5Rw/yYx/r6Sssor/3D7Gq+MB7Vq3YtbEvgzrEc1NL67igbc28M/rh39n7KaySnlxRQaZ+UV0jQ6na1Q4XaJaM6hru3pbBjWpKv/3ziZCg4N49KohXquD06aN6sHunBPM/SqD3nFtuWF0gr9DMsbvLME0A6rK3fPWkXeilNd/ch79OkU6cp0L+8Uy+3sD+f1/t/H04t3cfUlfAI4WlXHP/HV8uSuPyNYhFJ789lmUuMgwXr5lFAO7nLbeXK0Wrs1mxe58fvuDIXSOau1IPZwy+8qBZOQV8cj7W+gdE8HYPjH+DskYv7LO4mZg6Y5cVmYcYfb3BjCsR3tHr/WTC3py9bBuPL5oJ59tOcSmrAImP/UVK9OP8McfnsOmRy5n66OX8/n9FzH3xmSCg4Sp/0ohNT2/3vOqKuv3H+N3H20lOaE914/q4Wg9nBAcJPx9+jB6xURwz/z15LpvHjCmpbIxmABXVaVMeuorissq+Pz+i2jlgwHmk+WVTP1XCrtzTlBRpcREhPLsjBG1PjNz4FgJN76win1HivnHtKTvDNirKtsPFfLhxgN8uPEge/OLaRsWwjt3jqWvQ60wX9hxqJApT3/Feb068tJNIwNy2h3TctggvwdaaoJ5b302s+av5+/TkrgqqZvPrnuwoIQf/vNr+sS15cnrkup9yPFYcRm3vLSadfuPMW1kd46XVJCRV8Te/CKKyioJDhLG9u7I5HO7cPngzkS3CfVZPZzyWupefvnuZv7vygHcdmHvszrX/iPFfLL5EFcP70ZMPf+fjWkMSzAeaIkJpqyiiol/W0ZEWAgf3X2+z/9Srqis8viW3JKySu57cz2fbztMfPtwEmMiSOwYwYDOkUwc1KnZ/eJUVe58fS2Lth5mwR1jG/2w6rHiMn7wzAoy84tp3SqI6aN6cPuFvQNufMo0XZZgPNASE8yrqXv5f+9u5sWbRzK+f2DMq1VVpS2my6iguJwr//ElwUHCB3efT1T4mT2EWV5ZxY3/XsWavUd57Npz+XJXHu+syyZYhGuS43nwsv60jzi9tbc5u4C/fLqDWy/oyQV9baVXUz9LMB5oaQmmuKyCix5bSs+OEbx5++jTpnsxTcOavUeY+q9UVJXYyDC6RIXTLTqcmLahRLUJJSq8FVHhrejXqS3ndPt22h7X7dqbmbdqH3+bOpQfDo8HXN1lzy3bw5ur9xPdphW/+8E5XDGk8zfHvLAikz99vI3ySqVNaDDzbh3dJOeTM01HQCcYEQkG0oBsVZ1cY98TwHj3xzZAnKpGu/f1AOYC3QEFrlTVzLqu09ISzDNLdvPYpztY8NMxJCd28Hc4ph6p6fmk7MnnwLESDhSUcPDYSfJOlHK82u3cAEO6teOG0QlMGdqN+av38ZsPtnLnxb156IoBp51z28HjPPDWBrYcOM6UoV2ZNbEvv/9oG4u35zBxYCceuqI/t7y0mpKyShbeMZbEmAhfVdcEmEBPMPcDyUC7mgmmRrm7gWGqeov781Lg96q6SETaAlWqWlzX8S0pwZRVVDH6j18wND6KF28e5e9wTCNVVimFJ8s5VlzOl7vzeC1lLzsOFxLZOoSi0gomDuzEczNG1NmlWF5ZxbNL9/DU4l2UVyqhwUH8YtJAbhyTgIiQnnuCa55LoW1YCAvvOLtpg0zzFbBP8otIPDAJ+D1wfwPFpwO/dh83CAhR1UUAqnrCyTgDzeLtORwpKuPGMYn+DsWcheAgIbpNKNFtQkmMiWDGeT1I23uUV1P2UniynCeuS6p3vKpVcBD3XNKXywZ34qUVmdwwJoHBXb+dkLRXbFv+PTOZHz2/klteWs2820bT1sEpfoypydEWjIgsAP4IRAIP1NWCEZEEIBWIV9VKEfkB8BOgDOgJfA48rKqVdV2rJbVgfvJyGhuzjvH1wxNsYkXToMXbD3PrK2sY2CWSOTck+2SyUhM4nGzBOPbbSUQmAzmqusaD4tOABdUSSAhwAfAAMBLoBdxUyzVuE5E0EUnLzc31TuBNXG5hKUt25HD18G6WXIxHJgzoxNwbk9mbV8yUp78iLfOIv0MyLYSTv6HGAVNEJBOYD0wQkdfqKDsNmFftcxawTlXTVbUCeBcYXvMgVZ2jqsmqmhwb2zJux3xvfTaVVcq1I+L9HYoJIOMHxPHOz8YS2boV059PZf6qff4OybQAjnXIqupsYDaAiFyMq4tsRs1yItIfaA+kVNu8GmgvIrGqmgtMwHUnWoumqryVlkVS92j6xAXuVCrGP/rERfLuneO4e/46Hn57E/NW72dw13YM6BxJ/06RDO0ebctHG6/yeR+LiDwqIlOqbZoOzNdqg0HurrIHgC9EZBMgwPO+jdR78k6U8lrqXiqrzm68a3P2cXYcLuQaa72YRopq04oXZibz4OX9CQsJ4qONB/nVe1u4bk4qP/zn1xSVVjR8EmM8ZA9a+sB9b67nnXXZPHBZP+6a0LfR5/nVe5uZv3o/q38x8YyfCjemNqrKoeMn+XJXHg8v3Mhlgzrzz+uHt5jZFkyADvIbl335xby/4QCRrUN48vNdbNh/rFHnKa2o5L31B7h8cGdLLsZrRIQuUeFMTe7OLyYN4pMth3jyi13+Dss0E5ZgHPbssj0EBwlv3zGWuMgw7n1zfaO6IT7fmkNBSbkN7hvH3DIukWtHxPOPL3bx0caD/g7HNAOWYBx0sKCEBWv2MzU5nr6dIvnbdUlk5hfxu4+2nvG5/pO2ny5RrRlnqyQah4gIv7t6CCMS2vPzt9azObvA3yGZAGcJxkFzlqdTpXC7ez2Q0b06cvuFvZm3aj+fbjnk0TlUlT9+vI1lO3OZPqoHwdY3bhwUFhLMczNG0KFNKLe8tJo9uTaJhmk8SzAeOFJURklZnZMI1CrvRCnzVu3jB0nd6N6hzTfb77+0H0O6tePhhRtJb+Afb2WVMvvtTfxrWTozRvfgZ+P7NCp+Y85EbGQYL98yiipVps1JZXdOob9DMgHKEkwDyiur+P5TX3HlP74k+1iJx8e98FUGpRVV3Dn+u6sZhoYE8fdpwxARrnkupc5B/9KKSu6et5b5q/dz94Q+/PaqIdZ6MT7Tt1Mk824djSpMm7OSXYctyZgzZwmmAZ9vPUz2sRKyjhZz7bNfk5FX1OAxBcXlvJKylyuHdKF3bNvT9veObcvCO8YSERbM9OdTWbbz22luVJVVGUeY+cIq/rvpEL+cNJCfX9bf1nsxPte3UyTzbxuNCEx/PpUdhyzJmDNjCaYBr6buJb59OG/fMY6TFVVc+1wK2w8dr7VsVZXy2ZZDzHxxFSdKK05rvVTXMyaChXeMJaFjBD9+aTVvrNzH88vTmfi3ZUz9Vwpbso/z12uH8pMLejlVNWMa1CeuLfNvG02QCDP+vZKCknJ/h2QCiD1oWY/dOYVM/Nty/veKAdxxcW925xRy/dyVnCyv4leTBxETGUZ4q2DahAazbv8xXvgqg4y8IrpFh3PPJX24bmSPBq9x/GQ5t7+yhpT0fABGJLRn2sjuTDq3C21CbWp10zRszi5gytNfceOYRB6ZMtjf4RgvCtj1YALda6n7CA0OYmqy69mTPnGRLPjpWH40N5Wfv7XhtPJD46N4avowvjeks8czHbdr3YqXbhnJwjXZJCe2p18nm2PMND1DukUxY3QCr6Rkcm1y/HfWnTGmLtaCqUNRaQWj//AFEwd14onrkr6zr6Sskoy8IkrKKygpq6K4rIK4dq0ZGh9lYyWm2SooLmfC40tJjIngrdvH2HQyzYS1YPzgvfUHKCytYMbohNP2hYcGM6hrOz9EZYz/RLVpxcPfG8CDCzaycG0W1yZ393dIpomzQf5aqCqvpGQyqEs7hveI9nc4xjQZ/zM8nuE9ovnTx9spKLYBf1O/Fp9gqqqU33ywhU+3HPpmjrC1+46y/VAhN4xJsC4vY6oJChIevWoIR4vLeHzRDn+HY5q4Ft9Fln2shAVpWby4IpPQ4CBG9+5I4clyIsNCuCqpq7/DM6bJGdItihtGJ/Bq6l5uHJNIn7jTn/UyBqwFQ/cObVj7q0t549bzuHFMAvuPFLNu3zGuG9ndbhM2pg53X9KX0JAg/rlkt79DMU2Y/QYFWgUHMbZ3DGN7x/DLyYM4cKyEmLZh/g7LmCYrpm0Y15+XwEtfZzJrYl8SOkb4OyTTBDneghGRYBFZJyIf1rLvCRFZ737tFJFjNfa3E5FsEXna6Tir6xodTmhIi2/cGVOv2y/sRXCQ8M8le/wdimmifPFbdBawrbYdqnqfqiapahLwFPB2jSK/BZY5HJ8xphHi2rVm+sjuLFybRdbRYn+HY5ogRxOMiMQDk4C5HhSfDsyrduwIoBPwmTPRGWPO1u0X9UYEnl1qrRhzOqdbME8CDwFV9RUSkQSgJ7DY/TkIeBx4sIHjbhORNBFJy83Nra+oMcYBXaPDuWZEd95Ky+JQwUl/h2OaGMcSjIhMBnJUdY0HxacBC1T11KpedwL/VdX99R2kqnNUNVlVk2NjY88yYmNMY9x5cW8qVXlumbVizHc52YIZB0wRkUxgPjBBRF6ro+w0qnWPAWOAu9zH/hW4UUT+5GCsxphG6t6hDT8c1o15q/axO8eWWDbfcizBqOpsVY1X1URcCWSxqs6oWU5E+gPtgZRqx16vqj3cxz4AvKKqDzsVqzHm7Mya2JfI1iFcPzeVTA8W5TMtg8/vxRWRR0VkSrVN04H52lymdTamBYpv34bXfzKasooqfvR8KvuP2F1lxqbrN8Z40ebsAn70fCpRbVrx5m1j6Bod7u+QTAOcnK7fniY0xnjNkG5RvPrj8zhWVM71c1dypKjM3yEZP7IEY4zxqqHdo3nx5pFk5BXxeupef4dj/MgSjDHG65ITOzC2d0feTNtPVVXz6IY3Z84SjDHGEdNG9SDraAlf7c7zdyjGTyzBGGMccfngTrRv04o3V9f7vLRpxizBGGMcERYSzA+Hx/PZ1kPknyj1dzjGDyzBGGMcM21kd8orlYVrs/wdivEDSzDGGMf07RTJiIT2zF+9n+byzJ3xnCUYY4yjpo3sTnpuEasyjvg7FONjlmCMMY6adG4XIsNCbLC/BbIEY4xxVJvQEKYkdeWjTQcpKC73dzjGhyzBGGMcN31UD0orqvjXclszpiWxBGOMcdyQblFMTY7n2WV7WL7TVp9tKSzBGGN84jdThtAvLpJ731xvyyu3EJZgjDE+ER4azDPXD+dkeSX3zFtHRWWVv0MyDrMEY4zxmT5xbfn91UNYlXmEJz7f6e9wjMMcTzAiEiwi60Tkw1r2PSEi692vnSJyzL09SURSRGSLiGwUkeucjtMY4xtXD4tn2sjuPLNkD8tsPKZZ80ULZhawrbYdqnqfqiapahLwFPC2e1cxcKOqDgauAJ4UkWgfxGqM8YFHpgymX6e2PLRgg9263Iw5mmBEJB6YBMz1oPh0YB6Aqu5U1V3u9weAHCDWqTiNMb7VulUwj1+bRN6JMn7z4RZ/h2Mc4nQL5kngIaDe0TwRSQB6Aotr2TcKCAVOu4FeRG4TkTQRScvNtaa2MYHknPgofnZxb95em82irYf9HY5xgGMJRkQmAzmqusaD4tOABapaWeMcXYBXgZtV9bQkpapzVDVZVZNjY62BY0yguWtCXwZ2acfstzdxtKjM3+EYL3OyBTMOmCIimcB8YIKIvFZH2Wm4u8dOEZF2wEfAL1U11cE4jTF+EhoSxOPXDuVYcRm/ft+6ypobxxKMqs5W1XhVTcSVQBar6oya5USkP9AeSKm2LRR4B3hFVd9yKkZjjP8N6tqOey7py/sbDvDxpoP+Dsd4kc+fgxGRR0VkSrVN04H5+t3FIqYCFwI3VbuNOcmngRpjfOaOi3szuGs7fvPBVorLKvwdjvESaS6LACUnJ2taWpq/wzDGNNKavUf4n2dTuGt8Hx64vL+/w2kxRGSNqiY7cW57kt8Y0ySMSOjA1cO6MWd5Onvzi/wdjvECSzDGmCbj4e8NICRY+N1HtT6bbQKMJRhjTJPRqV1r7prQh0VbD9u0/s2AJRhjTJPy4/N7ktCxDb/5YAvlNuNyQLMEY4xpUsJCgvl/kwaxJ7eIl7/O9Hc45ixYgjHGNDmXDIzjgr4xPL1kNydK7bblQGUJxhjT5IgI91/aj2PF5byWutff4ZhGsgRjjGmShvVoz4X9Ynl+ebo9fBmgLMEYY5qsWZf0Ib+ojNdT9/k7FNMIlmCMMU3WiIQOjOvTkX8tT6ekrLLhA0yTYgnGGNOkzbqkH3knSpm3yloxgcYSjDGmSRvVswOje3XguWV7OFlurZhAYgnGGNPk3XNJX3IKS/lP2n5/h2LOgCUYY0yTN6ZXR0Ymtue5pXuosKf7A4ZHCUZEeotImPv9xSJyj4hEOxuaMca4iAi3XtCLAwUn+XzbYX+HYzzkaQtmIVApIn2AfwM9gTcci8oYY2q4ZGAnukWH8/LX9uBloPA0wVSpagVwNfCkqt4HdPHkQBEJFpF1IvJhLfueqLZi5U4ROVZt30wR2eV+zfQwTmNMMxUcJMwYnUBKej47Dxf6OxzjAU8TTLmITAdmAqcSRSsPj50F1Lq4g6rep6pJqpoEPAW8DSAiHYBfA+cBo4Bfi0h7D69njGmmrhvZndCQIJsEM0B4mmBuBsYAv1fVDBHpCbzW0EEiEg9MAuZ6cI3pwDz3+8uBRap6RFWPAouAKzyM1RjTTHWICOWqoV15e202BSXl/g7HNMCjBKOqW1X1HlWd525JRKrqnzw49EngIaDe2z5EJAHXuM5i96ZuQPX7EbPc24wxLdzMsYmUlFeycE2Wv0MxDfD0LrKlItLO3XW1AXhRRP7WwDGTgRxVXePBJaYBC1T11FNUUksZreUat4lImoik5eba6nfGtARDukUxvEc0r6RkUlV12q8F04R42kUWparHgR8CL6rqCGBiA8eMA6aISCYwH5ggInV1q03j2+4xcLVYulf7HA8cqHmQqs5R1WRVTY6NjfWsJsaYgDdzbCKZ+cUs32V/WDZlniaYEBHpAkzl20H+eqnqbFWNV9VEXAlksarOqFlORPoD7YGUaps/BS4TkfbuLrnL3NuMMYbvDelCTNswG+xv4jxNMI/i+gW/R1VXi0gvYFdjLigij4rIlGqbpgPzVfWbtq6qHgF+C6x2vx51bzPGGEJDgpgxugdLduSyObvA3+GYOki13+sBLTk5WdPS0vwdhjHGRwpKyrnwL0sY3iOaF28e5e9wApaIrFHVZCfO7ekgf7yIvCMiOSJyWEQWum9BNsYYv4gKb8VPL+rNkh25rM60Do6myNMusheB94GuuG4X/sC9zRhj/OamsYnERobx2Cc7aC69Mc2JpwkmVlVfVNUK9+slwG7bMsb4VXhoMPdM6MOqzCMs22l3lDU1niaYPBGZ4Z5XLFhEZgD5TgZmjDGeuG5kD7p3COexT3fYczFNjKcJ5hZctygfAg4C1+CaPsYYY/wqNCSI+yb2Y8uB43y8+ZC/wzHVeDpVzD5VnaKqsaoap6o/wPXQpTHG+N1VSd3o16ktjy/aQaW1YpqMs1nR8n6vRWGMMWchOEi4e0Jf0nOLSNljvfdNxdkkmNrmCzPGGL+4dFAnIsNCeG99tr9DMW5nk2CsHWqMaTJatwrmiiGd+WTzIU6WVzZ8gHFcvQlGRApF5Hgtr0Jcz8QYY0yTcVVSNwpLK1i8PcffoRgaSDCqGqmq7Wp5RapqiK+CNMYYT4zp3ZG4yDDrJmsizqaLzBhjmpTgIOH7Q7uyZHsuBcW24qW/WYIxxjQrVyV1payyio83H/R3KC2eJRhjTLNyTrcoesVE8N7609YoND5mCcYY06yICFcldSM1I59DBSf9HU6LZgnGGNPsXJXUFVV4f4MN9vuT4wnGPTnmOhGpdallEZkqIltFZIuIvFFt+1/c27aJyD9ExB7sNMZ4JDEmgqHdo62bzM980YKZBWyrbYeI9AVmA+NUdTBwr3v7WGAccC4wBBgJXOSDWI0xzcQPkrqy5cBxdhwq9HcoLZajCca96uUkYG4dRW4FnlHVowCqeurpKAVaA6FAGNAKOOxkrMaY5uWqpG6EhgTxxsq9/g6lxXK6BfMk8BBQVcf+fkA/EVkhIqkicgWAqqYAS3AtDXAQ+FRVa20FGWNMbTpEhDL5nC4sXJtNUWmFv8NpkRxLMCIyGchR1TX1FAsB+gIXA9OBuSISLSJ9gIFAPK4lmieIyIW1XOM2EUkTkbTcXFvNzhjzXTPGJHCitIJ37cl+v3CyBTMOmCIimcB8XEnitRplsoD3VLVcVTOAHbgSztVAqqqeUNUTwMfA6JoXUNU5qpqsqsmxsbaCszHmu4Z1j2ZQl3a8mrIXVZuf19ccSzCqOltV41U1EZgGLFbVGTWKvQuMBxCRGFxdZunAPuAiEQkRkVa4Bviti8wYc0ZEhBvGJLD9UCFr9x31dzgtjs+fgxGRR0Vkivvjp0C+iGzFNebyoKrmAwuAPcAmYAOwQVU/8HWsxpjAd1VSVyLDQng1xQb7fU2aS7MxOTlZ09LS/B2GMaYJeuT9Lbyxch9fz55ATNswf4fTpIjIGlVNduLc9iS/MabZmzG6B2WVVfwnbb+/Q2lRLMEYY5q9PnGRjOnVkTdW7qOyqnn02gQCSzDGmBZhxugEso6W8OUue6TBVyzBGGNahImD4ohsHcKHG5vXOjGvpmTy/PJ0f4dRK0swxpgWISwkmEsHdeKzLYcoq6hrcpHA8/a6bBZvz2m4oB9YgjHGtBiTzunC8ZMVrNid5+9QvEJVSc8toldshL9DqZUlGGNMi3F+3xgiW4fw0abm0U12tLicgpJyesZYgjHGGL9qbt1k6bknAOgd29bPkdTOEowxpkVpTt1k6XlFANata6mXAAAUAUlEQVSCMcaYpqA5dZOl5xbRKliIbx/u71BqZQnGGNOiNKdusoy8E/To0IaQ4Kb5q7xpRmWMMQ5qLt1krjvImub4C1iCMca0QM2hm6yyStmbX0yvJjr+ApZgjDEtUHPoJss+WkJZZVWTfQYGLMEYY1qoQO8mS89z3aJsXWTGGNPEBHo3WXpu075FGSzBGGNaqEDvJsvIK6Jd6xA6RoT6O5Q6OZ5gRCRYRNaJyId17J8qIltFZIuIvFFtew8R+UxEtrn3JzodqzGmZfmmm2xP4HWTpeedoGdsW0TE36HUyRctmFnAttp2iEhfYDYwTlUHA/dW2/0K8JiqDgRGAU1zulBjTMA6v28MkWEh/DcAp/BPzy2idxPuHgOHE4yIxAOTgLl1FLkVeEZVjwKoao77uEFAiKoucm8/oarFTsZqjGl5TnWTfRpg3WTFZRUcLDjZpMdfwPkWzJPAQ0Bd31w/oJ+IrBCRVBG5otr2YyLytrt77TERCa55sIjcJiJpIpKWm2ur1BljztykcwOvmyzDPQdZU76DDBxMMCIyGchR1TX1FAsB+gIXA9OBuSIS7d5+AfAAMBLoBdxU82BVnaOqyaqaHBsb690KGGNahEDsJsto4pNcnuJkC2YcMEVEMoH5wAQRea1GmSzgPVUtV9UMYAeuhJMFrFPVdFWtAN4FhjsYqzGmhfrmbrKthwOmmywQblEGBxOMqs5W1XhVTQSmAYtVdUaNYu8C4wFEJAZX11g6sBpoLyKnmiUTgK1OxWqMadmuPKcLBSXlAdNNlpFXRLfocMJDTxs5aFJ8/hyMiDwqIlPcHz8F8kVkK7AEeFBV81W1Elf32BcisgkQ4Hlfx2qMaRku6BdY3WTpuSeafOsFXGMdjlPVpcBS9/tfVduuwP3uV81jFgHn+iI+Y0zLVr2b7A+VVbRqotPfA6gq6XlFXD2sm79DaVDT/b9ojDE+9E03WROfmyzvRBmFJysCogVjCcYYY3B1k7VrHcJba7L8HUq9AuUWZbAEY4wxgKubbNqoHnyy+RDZx0r8HU6d0nPdsyhbC8YYYwLHzLGJALz8daZf46hPRl4RoSFBdI0O93coDbIEY4wxbt2iw7liSGfmrdpHUWmFv8Op1Z7cIhI7tiE4qOlOcnmKJRhjjKnmx+f3pPBkBW+l7fd3KLXaebiQ3gEw/gKWYIwx5juG92jPsB7RvPh1JpVV6u9wvuNgQQn7jhQzIqG9v0PxiCUYY4yp4cfn92RvfjFfbDvs71C+Y2X6EQBG9+ro50g8YwnGGGNquGJwZ7pFh/PvrzL8Hcp3rMzIJ7J1CAO7tPN3KB6xBGOMMTWEBAcxc2wCKzOOsDm7wN/hfCM1/Qjn9ewQEAP8YAnGGGNqdd3IHkSEBvPssj3+DgWAQwUnycgrCpjuMbAEY4wxtYoKb8XN43ry0caDrN9/zN/hsDIjHwic8RewBGOMMXX66cW9iWkbyh8+2oZrbl7/SU0/ElDjL2AJxhhj6tQ2LIR7J/ZjVeYRPtvq3zvKVqbnMyoxcMZfwBKMMcbUa9rI7vSOjeDPH2+nvNI/K14ePn6S9AAbfwFLMMYYU6+Q4CD+78qBpOcVMW/VPr/EkJoeeOMv4IMEIyLBIrJORD6sY/9UEdkqIltE5I0a+9qJSLaIPO10nMYYU5cJA+IY3asDT36+i+Mny31+/dT0I0SGhTCoa+CMv4BvWjCzgG217RCRvsBsYJyqDgburVHkt8AyZ8Mzxpj6iQi/uHIQR4rKeHap729bXpmRz8gAev7lFEcTjIjEA5OAuXUUuRV4RlWPAqhqTrVjRwCdgM+cjNEYYzxxTnwUk8/twmspe30603LO8ZOk5xYxulcHn13TW5xuwTwJPATUNTLWD+gnIitEJFVErgAQkSDgceDB+k4uIreJSJqIpOXm5nozbmOMOc0t5/eksLSCt9f6btXL1IzAmn+sOscSjIhMBnJUdU09xUKAvsDFwHRgrohEA3cC/1XVeufLVtU5qpqsqsmxsbFeitwYY2o3rHs058ZH8XLKXp89F5Oanu8afwmg519OcbIFMw6YIiKZwHxggoi8VqNMFvCeqparagawA1fCGQPc5T72r8CNIvInB2M1xpgGiQgzxySyO+cEK3bn++Saqen5JCe2JyQ48G76dSxiVZ2tqvGqmghMAxar6owaxd4FxgOISAyuLrN0Vb1eVXu4j30AeEVVH3YqVmOM8dTkoV3oGBHKSz5YVnnrgeOk5xYxfkCc49dygs9Toog8KiJT3B8/BfJFZCuwBHhQVX3zZ4ExxjRCWEgw00f14Ivth9l/pNjRay1Yk0VocBDfP7ero9dxik8SjKouVdXJ7ve/UtX33e9VVe9X1UGqeo6qzq/l2JdU9S5fxGmMMZ64fnQPgkR4NXWvY9coq6ji3fXZTBwUR/uIUMeu46TA69Qzxhg/6xIVzuWDO/Hm6v2UlFU6co0lO3I4UlTGtSO6O3J+X7AEY4wxjTBzTCIFJeW8tz7bkfO/lZZFXGQYF/SNceT8vmAJxhhjGmFUzw4M6BzJCysyqKzy7i3LuYWlLNmRw9XDuwXk3WOnBG7kxhjjRyLCz8b3YefhEyxc490HL99bn01llXLtiHivntfXLMEYY0wjTT63C8N6RPPXz3Z4bfoYVeWttCySukfTJy7SK+f0F0swxhjTSCLCLycNJKewlDnL071yzs3Zx9lxuJBrArz1ApZgjDHmrIxI6MCkc7swZ3k6hwpOnvX53lqzn9CQIL4/NDCffanOEowxxpylh68YQGWV8tfPdpzVeUrKKnlv/QEuH9yZqPBWXorOfyzBGGPMWereoQ03jUtk4dosthwoaPR5Xvo6k4KScmaOSfBidP5jCcYYY7zgZ+P7EB3eit9/tK1RMy0XlJTz3LI9jO8fS3Ji4K39UhtLMMYY4wVR4a24d2I/vt6Tz+LtOQ0fUMOc5XsoKCnngcv7OxCdf1iCMcYYL/nReT3oFRPBH/67jYrKutZZPF1uYSkvfJXJ94d2ZXDXKAcj9C1LMMYY4yWtgoN4+HsD2JNbxLzV9a6X+B3PLNlNWWUV91/az8HofM8SjDHGeNGlgzoxqmcHnly0k8KT5Q2W33+kmNdX7mVqcnd6xkT4IELfsQRjjDFedOrhy/yiMp5btqfB8k9+vosgEWZd0tcH0fmWJRhjjPGyc+Oj+UFSV+Z+mcGBYyV1lluz9wjvrMti5thEOke19mGEvuF4ghGRYBFZJyIf1rF/qohsFZEtIvKGe1uSiKS4t20UkeucjtMYY7zpgcv7o8BfP6394cuc4ye547W1dO/Qhp+N7+Pb4HwkxAfXmAVsA9rV3CEifYHZwDhVPSoipxaeLgZuVNVdItIVWCMin6rqMR/Ea4wxZy2+fRt+fH5Pnl26h4SOEdxzSR9EBHCtVnnn62spPFnBKz8e1Sye2q+Noy0YEYkHJgFz6yhyK/CMqh4FUNUc9393quou9/sDQA4Q62SsxhjjbfdO7MsPh3Xjic93ctcb6yguc824/LuPtpK29yh/vuZcBnQ+7W/vZsPpFsyTwENAXXNO9wMQkRVAMPCIqn5SvYCIjAJCgYZHy4wxpgkJCwnm8alDGdilHX/8eBsZeUVMHtqFV1L2cusFPZnSDCa0rI9jLRgRmQzkqOqaeoqFAH2Bi4HpwFwRia52ji7Aq8DNqnraU0sicpuIpIlIWm5urlfjN8YYbxARbr2wF/++aST7jxTzl092MLZ3R/73igH+Ds1xTnaRjQOmiEgmMB+YICKv1SiTBbynquWqmgHswJVwEJF2wEfAL1U1tbYLqOocVU1W1eTYWOtBM8Y0XeP7x/HOz8Zx87hEnpo+LKCXQvaUYzVU1dmqGq+qicA0YLGqzqhR7F1gPICIxODqMksXkVDgHeAVVX3LqRiNMcaX+sS15dffH0zHtmH+DsUnfJ5CReRREZni/vgpkC8iW4ElwIOqmg9MBS4EbhKR9e5Xkq9jNcYY03jSmGmlm6Lk5GRNS0vzdxjGGBNQRGSNqiY7ce7m3wlojDHGLyzBGGOMcYQlGGOMMY6wBGOMMcYRlmCMMcY4whKMMcYYRzSb25RFJBfYW2NzFFBwhtsaeh8D5DUyzNqufSZlPKmPr+rSUKwNlTnTutT8fOp99W323XgWa0Nl7Lvx7++A+so5UZcIVXVmKhRVbbYvYM6ZbmvoPZDmzXjOpIwn9fFVXc62Pmdal3rqUH2bfTf23TTp78aTunjzu3H656yhV3PvIvugEds8ee/NeM6kjCf18VVdPD1PXWXOtC41P39QR5nGsu+m/u323fjud0B95ZpSXRrUbLrIfEVE0tShp159rTnVBZpXfZpTXaB51cfq4rnm3oJxwhx/B+BFzaku0Lzq05zqAs2rPlYXD1kLxhhjjCOsBWOMMcYRLTrBiMgLIpIjIpsbcewIEdkkIrtF5B8iItX23S0iO0Rki4j8xbtR1xmP1+siIo+ISHa1JROu9H7kdcbkyHfj3v+AiKh7DSLHOfTd/FZENrq/l89ExCdr7zpUl8dEZLu7Pu9UX9XWaQ7V51r3v/0qEXF8rOZs6lDH+WaKyC73a2a17fX+u6qVk7eoNfUXrjVnhgObG3HsKmAMIMDHwPfc28cDnwNh7s9xAVyXR4AHmst3497XHdc6RHuBmECtC9CuWpl7gOcCuC6XASHu938G/hzIP2fAQKA/sBRIbqp1cMeXWGNbByDd/d/27vft66tvfa8W3YJR1eXAkerbRKS3iHwiImtE5EsROW3hbBHpgusfeIq6/s+/AvzAvfsO4E+qWuq+Ro6ztXBxqC5+42B9ngAeAnw2+OhEXVT1eLWiEfioPg7V5TNVrXAXTQXina3FtxyqzzZV3eGL+N3Xa1Qd6nA5sEhVj6jqUWARcEVjf0+06ARThznA3ao6AngA+GctZboBWdU+Z7m3gWvZ5wtEZKWILBORkY5GW7+zrQvAXe6uixdEpL1zoXrkrOojrpVUs1V1g9OBeuCsvxsR+b2I7AeuB37lYKwN8cbP2Sm34Prr2J+8WR9/8aQOtekG7K/2+VS9GlXfEA8v2iKISFtgLPBWte7F2hbPrq3v8dRfkCG4mpajgZHAf0Sklzvr+4yX6vIs8Fv3598Cj+P6BeBzZ1sfEWkD/AJXd4xfeem7QVV/AfxCRGYDdwG/9nKoDfJWXdzn+gVQAbzuzRjPhDfr4y/11UFEbgZmubf1Af4rImVAhqpeTd31alR9LcF8VxBwTFWTqm8UkWBgjfvj+7h+8VZvxscDB9zvs4C33QlllYhU4ZrvJ9fJwGtx1nVR1cPVjnse+NDJgBtwtvXpDfQENrj/0cUDa0VklKoecjj2mrzxc1bdG8BH+CHB4KW6uAeTJwOX+PqPsRq8/d34Q611AFDVF4EXAURkKXCTqmZWK5IFXFztczyusZosGlNfpwegmvoLSKTa4BjwNXCt+70AQ+s4bjWuVsqpAa8r3dt/Cjzqft8PV3NTArQuXaqVuQ+YH8jfTY0ymfhokN+h76ZvtTJ3AwsCuC5XAFuBWF/+fDn9c4aPBvkbWwfqHuTPwNUL0979voMn9a01Ln98oU3lBcwDDgLluDL0j3H9lfsJsMH9Q/+rOo5NBjYDe4Cn+fah1VDgNfe+tcCEAK7Lq8AmYCOuv9q6+KIuTtWnRplMfHcXmRPfzUL39o245pXqFsB12Y3rD7H17pdP7ohzsD5Xu89VChwGPm2KdaCWBOPefov7O9kN3NxQfet72ZP8xhhjHGF3kRljjHGEJRhjjDGOsARjjDHGEZZgjDHGOMISjDHGGEdYgjHNmoic8PH15orIIC+dq1JcsyVvFpEPGpplWESiReROb1zbGG+w25RNsyYiJ1S1rRfPF6LfTszoqOqxi8jLwE5V/X095ROBD1V1iC/iM6Yh1oIxLY6IxIrIQhFZ7X6Nc28fJSJfi8g693/7u7ffJCJvicgHwGcicrGILBWRBeJax+T1U2tjuLcnu9+fcE9IuUFEUkWkk3t7b/fn1SLyqIetrBS+nbSzrYh8ISJrxbU+x1XuMn8CertbPY+5yz7ovs5GEfmNF/83GtMgSzCmJfo78ISqjgT+B5jr3r4duFBVh+GanfgP1Y4ZA8xU1Qnuz8OAe4FBQC9gXC3XiQBSVXUosBy4tdr1/+6+foPzObnnwboE12wKACeBq1V1OK71hx53J7iHgT2qmqSqD4rIZUBfYBSQBIwQkQsbup4x3mKTXZqWaCIwqNpMs+1EJBKIAl4Wkb64ZoptVe2YRapafc2NVaqaBSAi63HNBfVVjeuU8e0EoWuAS93vx/DtWhpvAH+tI87waudeg2ttDnDNBfUHd7KowtWy6VTL8Ze5X+vcn9viSjjL67ieMV5lCca0REHAGFUtqb5RRJ4Clqjq1e7xjKXVdhfVOEdptfeV1P5vqVy/HeSsq0x9SlQ1SUSicCWqnwH/wLX+SywwQlXLRSQTaF3L8QL8UVX/dYbXNcYrrIvMtESf4Vo/BQAROTWteRSQ7X5/k4PXT8XVNQcwraHCqlqAa1nkB0SkFa44c9zJZTyQ4C5aCERWO/RT4Bb3+iCISDcRifNSHYxpkCUY09y1EZGsaq/7cf2yTnYPfG/FtcQCwF+AP4rICiDYwZjuBe4XkVVAF6CgoQNUdR2umXGn4VqQK1lE0nC1Zra7y+QDK9y3NT+mqp/h6oJLEZFNwAK+m4CMcZTdpmyMj7lX1yxRVRWRacB0Vb2qoeOMCTQ2BmOM740Annbf+XUMPy1DbYzTrAVjjDHGETYGY4wxxhGWYIwxxjjCEowxxhhHWIIxxhjjCEswxhhjHGEJxhhjjCP+P5wZ6f+TIFHIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:57 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>4.239694</th>\n",
       "    <th>4.260919</th>\n",
       "    <th>0.227276</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>4.698368</th>\n",
       "    <th>4.491120</th>\n",
       "    <th>0.214072</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>4.531708</th>\n",
       "    <th>4.330137</th>\n",
       "    <th>0.222841</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>4.199453</th>\n",
       "    <th>4.125905</th>\n",
       "    <th>0.238470</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>3.972861</th>\n",
       "    <th>4.049260</th>\n",
       "    <th>0.246269</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-1, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('austen_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (9614 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (9614 items)\n",
       "[Text xxbos xxmaj sir xxmaj walter xxmaj elliot , of xxmaj kellynch xxmaj hall , in xxmaj somersetshire , was a man who , for his own amusement , never took up any book but the xxmaj xxunk ; there he found occupation for an idle hour , and consolation in a distressed one ; there his xxunk were roused into admiration and respect , by contemplating the limited remnant of the earliest xxunk ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless xxunk of the last century ; and there , if every other leaf were xxunk , he could read his own history with an interest which never failed . xxmaj this was the page at which the favourite volume always opened :, Text xxbos \" xxup elliot xxup of xxup kellynch xxup hall ., Text xxbos \" xxmaj walter xxmaj elliot , born xxmaj march xxunk , xxunk , married , xxmaj july xxunk , xxunk , xxmaj elizabeth , daughter of xxmaj james xxmaj xxunk , xxmaj esq . of xxmaj south xxmaj park , in the county of xxmaj xxunk , by which lady ( who died xxunk ) he has issue xxmaj elizabeth , born xxmaj june xxunk , xxunk ; xxmaj anne , born xxmaj august xxunk , xxunk ; a still - born son , xxmaj november 5 , xxunk ; xxmaj mary , born xxmaj november xxunk , xxunk . \", Text xxbos xxmaj then followed the history and rise of the ancient and respectable family , in the usual terms ; how it had been first settled in xxmaj xxunk ; how mentioned in xxmaj xxunk , serving the office of high xxunk , representing a xxunk in three successive xxunk , exertions of xxunk , and dignity of baronet , in the first year of xxmaj charles xxup ii , with all the xxmaj xxunk and xxmaj xxunk they had married ; forming altogether two handsome xxunk pages , and concluding with the arms and xxunk seat , xxmaj kellynch xxmaj hall , in the county of xxmaj somerset , \" and xxmaj sir xxmaj walter 's handwriting again in this xxunk, Text xxbos \" xxmaj heir xxunk , xxmaj william xxmaj walter xxmaj elliot , xxmaj esq . , great xxunk of the second xxmaj sir xxmaj walter . \"]...\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (1068 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (1068 items)\n",
       "[Text xxbos xxmaj serious she was , very serious in her xxunk , and in her resolutions ; and yet there was no preventing a laugh , sometimes in the very midst of them . xxmaj she must laugh at such a close ! xxmaj such an end of the xxunk disappointment of five weeks back ! xxmaj such a heart -- such a xxmaj harriet !, Text xxbos xxmaj he told xxmaj fanny of it . xxmaj she knew so much already , that she must know everything . xxmaj it made the substance of one other confidential discourse about xxmaj miss xxmaj crawford ; and xxmaj fanny was the more affected from feeling it to be the last time in which xxmaj miss xxmaj crawford 's name would ever be mentioned between them with any remains of liberty . xxmaj once afterwards she was alluded to by him . xxmaj lady xxmaj bertram had been telling her niece in the evening to write to her soon and often , and promising to be a good correspondent herself ; and xxmaj edmund , at a convenient moment , then added in a whisper , \" xxmaj and _ i _ shall write to you , xxmaj fanny , when i have anything worth writing about , anything to say that i think you will like to hear , and that you will not hear so soon from any other quarter . \" xxmaj had she doubted his meaning while she listened , the glow in his face , when she looked up at him , would have been decisive ., Text xxbos \" i should be puzzled to spend so large a fortune myself , \" said xxmaj mrs. xxmaj dashwood , \" if my children were all to be rich without my help . \", Text xxbos \" i do not think it _ is _ so very small . xxmaj we shall not be many , you know . \", Text xxbos xxmaj this could not be denied , and xxmaj fanny was silenced . xxmaj after another pause , he went xxunk , xxmaj miss xxmaj price , are you such a great admirer of this xxmaj mr. xxmaj crawford as some people are ? xxmaj for my part , i can see nothing in him . \"]...\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(7706, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(7706, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7ff571bc3048>, metrics=[<function accuracy at 0x7ff578f68ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer(learn=LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (9614 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (9614 items)\n",
       "[Text xxbos xxmaj sir xxmaj walter xxmaj elliot , of xxmaj kellynch xxmaj hall , in xxmaj somersetshire , was a man who , for his own amusement , never took up any book but the xxmaj xxunk ; there he found occupation for an idle hour , and consolation in a distressed one ; there his xxunk were roused into admiration and respect , by contemplating the limited remnant of the earliest xxunk ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless xxunk of the last century ; and there , if every other leaf were xxunk , he could read his own history with an interest which never failed . xxmaj this was the page at which the favourite volume always opened :, Text xxbos \" xxup elliot xxup of xxup kellynch xxup hall ., Text xxbos \" xxmaj walter xxmaj elliot , born xxmaj march xxunk , xxunk , married , xxmaj july xxunk , xxunk , xxmaj elizabeth , daughter of xxmaj james xxmaj xxunk , xxmaj esq . of xxmaj south xxmaj park , in the county of xxmaj xxunk , by which lady ( who died xxunk ) he has issue xxmaj elizabeth , born xxmaj june xxunk , xxunk ; xxmaj anne , born xxmaj august xxunk , xxunk ; a still - born son , xxmaj november 5 , xxunk ; xxmaj mary , born xxmaj november xxunk , xxunk . \", Text xxbos xxmaj then followed the history and rise of the ancient and respectable family , in the usual terms ; how it had been first settled in xxmaj xxunk ; how mentioned in xxmaj xxunk , serving the office of high xxunk , representing a xxunk in three successive xxunk , exertions of xxunk , and dignity of baronet , in the first year of xxmaj charles xxup ii , with all the xxmaj xxunk and xxmaj xxunk they had married ; forming altogether two handsome xxunk pages , and concluding with the arms and xxunk seat , xxmaj kellynch xxmaj hall , in the county of xxmaj somerset , \" and xxmaj sir xxmaj walter 's handwriting again in this xxunk, Text xxbos \" xxmaj heir xxunk , xxmaj william xxmaj walter xxmaj elliot , xxmaj esq . , great xxunk of the second xxmaj sir xxmaj walter . \"]...\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (1068 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (1068 items)\n",
       "[Text xxbos xxmaj serious she was , very serious in her xxunk , and in her resolutions ; and yet there was no preventing a laugh , sometimes in the very midst of them . xxmaj she must laugh at such a close ! xxmaj such an end of the xxunk disappointment of five weeks back ! xxmaj such a heart -- such a xxmaj harriet !, Text xxbos xxmaj he told xxmaj fanny of it . xxmaj she knew so much already , that she must know everything . xxmaj it made the substance of one other confidential discourse about xxmaj miss xxmaj crawford ; and xxmaj fanny was the more affected from feeling it to be the last time in which xxmaj miss xxmaj crawford 's name would ever be mentioned between them with any remains of liberty . xxmaj once afterwards she was alluded to by him . xxmaj lady xxmaj bertram had been telling her niece in the evening to write to her soon and often , and promising to be a good correspondent herself ; and xxmaj edmund , at a convenient moment , then added in a whisper , \" xxmaj and _ i _ shall write to you , xxmaj fanny , when i have anything worth writing about , anything to say that i think you will like to hear , and that you will not hear so soon from any other quarter . \" xxmaj had she doubted his meaning while she listened , the glow in his face , when she looked up at him , would have been decisive ., Text xxbos \" i should be puzzled to spend so large a fortune myself , \" said xxmaj mrs. xxmaj dashwood , \" if my children were all to be rich without my help . \", Text xxbos \" i do not think it _ is _ so very small . xxmaj we shall not be many , you know . \", Text xxbos xxmaj this could not be denied , and xxmaj fanny was silenced . xxmaj after another pause , he went xxunk , xxmaj miss xxmaj price , are you such a great admirer of this xxmaj mr. xxmaj crawford as some people are ? xxmaj for my part , i can see nothing in him . \"]...\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(7706, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(7706, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7ff571bc3048>, metrics=[<function accuracy at 0x7ff578f68ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(7706, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7706, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")]), bptt=70, alpha=2.0, beta=1.0, adjust=False)], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(7706, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7706, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('austen_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 08:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.937418</th>\n",
       "    <th>4.045618</th>\n",
       "    <th>0.244564</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>4.034586</th>\n",
       "    <th>4.111759</th>\n",
       "    <th>0.240186</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>4.176316</th>\n",
       "    <th>4.183969</th>\n",
       "    <th>0.232782</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>4.159773</th>\n",
       "    <th>4.145462</th>\n",
       "    <th>0.235289</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>4.080376</th>\n",
       "    <th>4.101871</th>\n",
       "    <th>0.241351</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>3.998302</th>\n",
       "    <th>4.053368</th>\n",
       "    <th>0.244966</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>3.845542</th>\n",
       "    <th>3.973496</th>\n",
       "    <th>0.253084</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>3.701439</th>\n",
       "    <th>3.928024</th>\n",
       "    <th>0.257661</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>3.588448</th>\n",
       "    <th>3.901617</th>\n",
       "    <th>0.261417</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>3.512392</th>\n",
       "    <th>3.900527</th>\n",
       "    <th>0.261204</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 5e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('austen_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (9614 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (9614 items)\n",
       "[Text xxbos xxmaj sir xxmaj walter xxmaj elliot , of xxmaj kellynch xxmaj hall , in xxmaj somersetshire , was a man who , for his own amusement , never took up any book but the xxmaj xxunk ; there he found occupation for an idle hour , and consolation in a distressed one ; there his xxunk were roused into admiration and respect , by contemplating the limited remnant of the earliest xxunk ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless xxunk of the last century ; and there , if every other leaf were xxunk , he could read his own history with an interest which never failed . xxmaj this was the page at which the favourite volume always opened :, Text xxbos \" xxup elliot xxup of xxup kellynch xxup hall ., Text xxbos \" xxmaj walter xxmaj elliot , born xxmaj march xxunk , xxunk , married , xxmaj july xxunk , xxunk , xxmaj elizabeth , daughter of xxmaj james xxmaj xxunk , xxmaj esq . of xxmaj south xxmaj park , in the county of xxmaj xxunk , by which lady ( who died xxunk ) he has issue xxmaj elizabeth , born xxmaj june xxunk , xxunk ; xxmaj anne , born xxmaj august xxunk , xxunk ; a still - born son , xxmaj november 5 , xxunk ; xxmaj mary , born xxmaj november xxunk , xxunk . \", Text xxbos xxmaj then followed the history and rise of the ancient and respectable family , in the usual terms ; how it had been first settled in xxmaj xxunk ; how mentioned in xxmaj xxunk , serving the office of high xxunk , representing a xxunk in three successive xxunk , exertions of xxunk , and dignity of baronet , in the first year of xxmaj charles xxup ii , with all the xxmaj xxunk and xxmaj xxunk they had married ; forming altogether two handsome xxunk pages , and concluding with the arms and xxunk seat , xxmaj kellynch xxmaj hall , in the county of xxmaj somerset , \" and xxmaj sir xxmaj walter 's handwriting again in this xxunk, Text xxbos \" xxmaj heir xxunk , xxmaj william xxmaj walter xxmaj elliot , xxmaj esq . , great xxunk of the second xxmaj sir xxmaj walter . \"]...\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (1068 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (1068 items)\n",
       "[Text xxbos xxmaj serious she was , very serious in her xxunk , and in her resolutions ; and yet there was no preventing a laugh , sometimes in the very midst of them . xxmaj she must laugh at such a close ! xxmaj such an end of the xxunk disappointment of five weeks back ! xxmaj such a heart -- such a xxmaj harriet !, Text xxbos xxmaj he told xxmaj fanny of it . xxmaj she knew so much already , that she must know everything . xxmaj it made the substance of one other confidential discourse about xxmaj miss xxmaj crawford ; and xxmaj fanny was the more affected from feeling it to be the last time in which xxmaj miss xxmaj crawford 's name would ever be mentioned between them with any remains of liberty . xxmaj once afterwards she was alluded to by him . xxmaj lady xxmaj bertram had been telling her niece in the evening to write to her soon and often , and promising to be a good correspondent herself ; and xxmaj edmund , at a convenient moment , then added in a whisper , \" xxmaj and _ i _ shall write to you , xxmaj fanny , when i have anything worth writing about , anything to say that i think you will like to hear , and that you will not hear so soon from any other quarter . \" xxmaj had she doubted his meaning while she listened , the glow in his face , when she looked up at him , would have been decisive ., Text xxbos \" i should be puzzled to spend so large a fortune myself , \" said xxmaj mrs. xxmaj dashwood , \" if my children were all to be rich without my help . \", Text xxbos \" i do not think it _ is _ so very small . xxmaj we shall not be many , you know . \", Text xxbos xxmaj this could not be denied , and xxmaj fanny was silenced . xxmaj after another pause , he went xxunk , xxmaj miss xxmaj price , are you such a great admirer of this xxmaj mr. xxmaj crawford as some people are ? xxmaj for my part , i can see nothing in him . \"]...\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(7706, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(7706, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7fd2e5e0b048>, metrics=[<function accuracy at 0x7fd3095f2ae8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer(learn=LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (9614 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (9614 items)\n",
       "[Text xxbos xxmaj sir xxmaj walter xxmaj elliot , of xxmaj kellynch xxmaj hall , in xxmaj somersetshire , was a man who , for his own amusement , never took up any book but the xxmaj xxunk ; there he found occupation for an idle hour , and consolation in a distressed one ; there his xxunk were roused into admiration and respect , by contemplating the limited remnant of the earliest xxunk ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless xxunk of the last century ; and there , if every other leaf were xxunk , he could read his own history with an interest which never failed . xxmaj this was the page at which the favourite volume always opened :, Text xxbos \" xxup elliot xxup of xxup kellynch xxup hall ., Text xxbos \" xxmaj walter xxmaj elliot , born xxmaj march xxunk , xxunk , married , xxmaj july xxunk , xxunk , xxmaj elizabeth , daughter of xxmaj james xxmaj xxunk , xxmaj esq . of xxmaj south xxmaj park , in the county of xxmaj xxunk , by which lady ( who died xxunk ) he has issue xxmaj elizabeth , born xxmaj june xxunk , xxunk ; xxmaj anne , born xxmaj august xxunk , xxunk ; a still - born son , xxmaj november 5 , xxunk ; xxmaj mary , born xxmaj november xxunk , xxunk . \", Text xxbos xxmaj then followed the history and rise of the ancient and respectable family , in the usual terms ; how it had been first settled in xxmaj xxunk ; how mentioned in xxmaj xxunk , serving the office of high xxunk , representing a xxunk in three successive xxunk , exertions of xxunk , and dignity of baronet , in the first year of xxmaj charles xxup ii , with all the xxmaj xxunk and xxmaj xxunk they had married ; forming altogether two handsome xxunk pages , and concluding with the arms and xxunk seat , xxmaj kellynch xxmaj hall , in the county of xxmaj somerset , \" and xxmaj sir xxmaj walter 's handwriting again in this xxunk, Text xxbos \" xxmaj heir xxunk , xxmaj william xxmaj walter xxmaj elliot , xxmaj esq . , great xxunk of the second xxmaj sir xxmaj walter . \"]...\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (1068 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (1068 items)\n",
       "[Text xxbos xxmaj serious she was , very serious in her xxunk , and in her resolutions ; and yet there was no preventing a laugh , sometimes in the very midst of them . xxmaj she must laugh at such a close ! xxmaj such an end of the xxunk disappointment of five weeks back ! xxmaj such a heart -- such a xxmaj harriet !, Text xxbos xxmaj he told xxmaj fanny of it . xxmaj she knew so much already , that she must know everything . xxmaj it made the substance of one other confidential discourse about xxmaj miss xxmaj crawford ; and xxmaj fanny was the more affected from feeling it to be the last time in which xxmaj miss xxmaj crawford 's name would ever be mentioned between them with any remains of liberty . xxmaj once afterwards she was alluded to by him . xxmaj lady xxmaj bertram had been telling her niece in the evening to write to her soon and often , and promising to be a good correspondent herself ; and xxmaj edmund , at a convenient moment , then added in a whisper , \" xxmaj and _ i _ shall write to you , xxmaj fanny , when i have anything worth writing about , anything to say that i think you will like to hear , and that you will not hear so soon from any other quarter . \" xxmaj had she doubted his meaning while she listened , the glow in his face , when she looked up at him , would have been decisive ., Text xxbos \" i should be puzzled to spend so large a fortune myself , \" said xxmaj mrs. xxmaj dashwood , \" if my children were all to be rich without my help . \", Text xxbos \" i do not think it _ is _ so very small . xxmaj we shall not be many , you know . \", Text xxbos xxmaj this could not be denied , and xxmaj fanny was silenced . xxmaj after another pause , he went xxunk , xxmaj miss xxmaj price , are you such a great admirer of this xxmaj mr. xxmaj crawford as some people are ? xxmaj for my part , i can see nothing in him . \"]...\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(7706, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(7706, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7fd2e5e0b048>, metrics=[<function accuracy at 0x7fd3095f2ae8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(7706, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7706, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")]), bptt=70, alpha=2.0, beta=1.0, adjust=False)], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(7706, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7706, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('austen_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 08:17 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.627517</th>\n",
       "    <th>3.872940</th>\n",
       "    <th>0.260884</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.811349</th>\n",
       "    <th>3.908757</th>\n",
       "    <th>0.256539</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.947198</th>\n",
       "    <th>3.961884</th>\n",
       "    <th>0.253102</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>3.959436</th>\n",
       "    <th>3.958192</th>\n",
       "    <th>0.252878</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>3.874309</th>\n",
       "    <th>3.908625</th>\n",
       "    <th>0.256876</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>3.769334</th>\n",
       "    <th>3.842035</th>\n",
       "    <th>0.265243</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>3.638984</th>\n",
       "    <th>3.796579</th>\n",
       "    <th>0.272708</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>3.459986</th>\n",
       "    <th>3.760848</th>\n",
       "    <th>0.276806</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>3.310060</th>\n",
       "    <th>3.757998</th>\n",
       "    <th>0.277940</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>3.209675</th>\n",
       "    <th>3.773574</th>\n",
       "    <th>0.277934</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(10, 5e-2, moms=(0.8, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('austen_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (9614 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (9614 items)\n",
       "[Text xxbos xxmaj sir xxmaj walter xxmaj elliot , of xxmaj kellynch xxmaj hall , in xxmaj somersetshire , was a man who , for his own amusement , never took up any book but the xxmaj xxunk ; there he found occupation for an idle hour , and consolation in a distressed one ; there his xxunk were roused into admiration and respect , by contemplating the limited remnant of the earliest xxunk ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless xxunk of the last century ; and there , if every other leaf were xxunk , he could read his own history with an interest which never failed . xxmaj this was the page at which the favourite volume always opened :, Text xxbos \" xxup elliot xxup of xxup kellynch xxup hall ., Text xxbos \" xxmaj walter xxmaj elliot , born xxmaj march xxunk , xxunk , married , xxmaj july xxunk , xxunk , xxmaj elizabeth , daughter of xxmaj james xxmaj xxunk , xxmaj esq . of xxmaj south xxmaj park , in the county of xxmaj xxunk , by which lady ( who died xxunk ) he has issue xxmaj elizabeth , born xxmaj june xxunk , xxunk ; xxmaj anne , born xxmaj august xxunk , xxunk ; a still - born son , xxmaj november 5 , xxunk ; xxmaj mary , born xxmaj november xxunk , xxunk . \", Text xxbos xxmaj then followed the history and rise of the ancient and respectable family , in the usual terms ; how it had been first settled in xxmaj xxunk ; how mentioned in xxmaj xxunk , serving the office of high xxunk , representing a xxunk in three successive xxunk , exertions of xxunk , and dignity of baronet , in the first year of xxmaj charles xxup ii , with all the xxmaj xxunk and xxmaj xxunk they had married ; forming altogether two handsome xxunk pages , and concluding with the arms and xxunk seat , xxmaj kellynch xxmaj hall , in the county of xxmaj somerset , \" and xxmaj sir xxmaj walter 's handwriting again in this xxunk, Text xxbos \" xxmaj heir xxunk , xxmaj william xxmaj walter xxmaj elliot , xxmaj esq . , great xxunk of the second xxmaj sir xxmaj walter . \"]...\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (1068 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (1068 items)\n",
       "[Text xxbos xxmaj serious she was , very serious in her xxunk , and in her resolutions ; and yet there was no preventing a laugh , sometimes in the very midst of them . xxmaj she must laugh at such a close ! xxmaj such an end of the xxunk disappointment of five weeks back ! xxmaj such a heart -- such a xxmaj harriet !, Text xxbos xxmaj he told xxmaj fanny of it . xxmaj she knew so much already , that she must know everything . xxmaj it made the substance of one other confidential discourse about xxmaj miss xxmaj crawford ; and xxmaj fanny was the more affected from feeling it to be the last time in which xxmaj miss xxmaj crawford 's name would ever be mentioned between them with any remains of liberty . xxmaj once afterwards she was alluded to by him . xxmaj lady xxmaj bertram had been telling her niece in the evening to write to her soon and often , and promising to be a good correspondent herself ; and xxmaj edmund , at a convenient moment , then added in a whisper , \" xxmaj and _ i _ shall write to you , xxmaj fanny , when i have anything worth writing about , anything to say that i think you will like to hear , and that you will not hear so soon from any other quarter . \" xxmaj had she doubted his meaning while she listened , the glow in his face , when she looked up at him , would have been decisive ., Text xxbos \" i should be puzzled to spend so large a fortune myself , \" said xxmaj mrs. xxmaj dashwood , \" if my children were all to be rich without my help . \", Text xxbos \" i do not think it _ is _ so very small . xxmaj we shall not be many , you know . \", Text xxbos xxmaj this could not be denied , and xxmaj fanny was silenced . xxmaj after another pause , he went xxunk , xxmaj miss xxmaj price , are you such a great admirer of this xxmaj mr. xxmaj crawford as some people are ? xxmaj for my part , i can see nothing in him . \"]...\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(7706, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(7706, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f485a806f98>, metrics=[<function accuracy at 0x7f4876a6c2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[RNNTrainer(learn=LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: LMLabel (9614 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (9614 items)\n",
       "[Text xxbos xxmaj sir xxmaj walter xxmaj elliot , of xxmaj kellynch xxmaj hall , in xxmaj somersetshire , was a man who , for his own amusement , never took up any book but the xxmaj xxunk ; there he found occupation for an idle hour , and consolation in a distressed one ; there his xxunk were roused into admiration and respect , by contemplating the limited remnant of the earliest xxunk ; there any unwelcome sensations , arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless xxunk of the last century ; and there , if every other leaf were xxunk , he could read his own history with an interest which never failed . xxmaj this was the page at which the favourite volume always opened :, Text xxbos \" xxup elliot xxup of xxup kellynch xxup hall ., Text xxbos \" xxmaj walter xxmaj elliot , born xxmaj march xxunk , xxunk , married , xxmaj july xxunk , xxunk , xxmaj elizabeth , daughter of xxmaj james xxmaj xxunk , xxmaj esq . of xxmaj south xxmaj park , in the county of xxmaj xxunk , by which lady ( who died xxunk ) he has issue xxmaj elizabeth , born xxmaj june xxunk , xxunk ; xxmaj anne , born xxmaj august xxunk , xxunk ; a still - born son , xxmaj november 5 , xxunk ; xxmaj mary , born xxmaj november xxunk , xxunk . \", Text xxbos xxmaj then followed the history and rise of the ancient and respectable family , in the usual terms ; how it had been first settled in xxmaj xxunk ; how mentioned in xxmaj xxunk , serving the office of high xxunk , representing a xxunk in three successive xxunk , exertions of xxunk , and dignity of baronet , in the first year of xxmaj charles xxup ii , with all the xxmaj xxunk and xxmaj xxunk they had married ; forming altogether two handsome xxunk pages , and concluding with the arms and xxunk seat , xxmaj kellynch xxmaj hall , in the county of xxmaj somerset , \" and xxmaj sir xxmaj walter 's handwriting again in this xxunk, Text xxbos \" xxmaj heir xxunk , xxmaj william xxmaj walter xxmaj elliot , xxmaj esq . , great xxunk of the second xxmaj sir xxmaj walter . \"]...\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList\n",
       "y: LMLabel (1068 items)\n",
       "[Category 0, Category 0, Category 0, Category 0, Category 0]...\n",
       "Path: .\n",
       "x: LMTextList (1068 items)\n",
       "[Text xxbos xxmaj serious she was , very serious in her xxunk , and in her resolutions ; and yet there was no preventing a laugh , sometimes in the very midst of them . xxmaj she must laugh at such a close ! xxmaj such an end of the xxunk disappointment of five weeks back ! xxmaj such a heart -- such a xxmaj harriet !, Text xxbos xxmaj he told xxmaj fanny of it . xxmaj she knew so much already , that she must know everything . xxmaj it made the substance of one other confidential discourse about xxmaj miss xxmaj crawford ; and xxmaj fanny was the more affected from feeling it to be the last time in which xxmaj miss xxmaj crawford 's name would ever be mentioned between them with any remains of liberty . xxmaj once afterwards she was alluded to by him . xxmaj lady xxmaj bertram had been telling her niece in the evening to write to her soon and often , and promising to be a good correspondent herself ; and xxmaj edmund , at a convenient moment , then added in a whisper , \" xxmaj and _ i _ shall write to you , xxmaj fanny , when i have anything worth writing about , anything to say that i think you will like to hear , and that you will not hear so soon from any other quarter . \" xxmaj had she doubted his meaning while she listened , the glow in his face , when she looked up at him , would have been decisive ., Text xxbos \" i should be puzzled to spend so large a fortune myself , \" said xxmaj mrs. xxmaj dashwood , \" if my children were all to be rich without my help . \", Text xxbos \" i do not think it _ is _ so very small . xxmaj we shall not be many , you know . \", Text xxbos xxmaj this could not be denied , and xxmaj fanny was silenced . xxmaj after another pause , he went xxunk , xxmaj miss xxmaj price , are you such a great admirer of this xxmaj mr. xxmaj crawford as some people are ? xxmaj for my part , i can see nothing in him . \"]...\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): RNNCore(\n",
       "    (encoder): Embedding(7706, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(7706, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<fastai.layers.FlattenedLoss object at 0x7f485a806f98>, metrics=[<function accuracy at 0x7f4876a6c2f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(7706, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7706, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")]), bptt=70, alpha=2.0, beta=1.0, adjust=False)], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(7706, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7706, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=7706, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('austen_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 10:13 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>3.195648</th>\n",
       "    <th>3.780437</th>\n",
       "    <th>0.277463</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.208839</th>\n",
       "    <th>3.762051</th>\n",
       "    <th>0.278742</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>3.205661</th>\n",
       "    <th>3.767136</th>\n",
       "    <th>0.277582</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>3.157184</th>\n",
       "    <th>3.758836</th>\n",
       "    <th>0.280707</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>3.074185</th>\n",
       "    <th>3.769739</th>\n",
       "    <th>0.280391</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>2.985107</th>\n",
       "    <th>3.786957</th>\n",
       "    <th>0.281848</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>2.913245</th>\n",
       "    <th>3.806770</th>\n",
       "    <th>0.280715</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>2.852356</th>\n",
       "    <th>3.811906</th>\n",
       "    <th>0.280843</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>2.801916</th>\n",
       "    <th>3.832476</th>\n",
       "    <th>0.279228</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>2.775792</th>\n",
       "    <th>3.833936</th>\n",
       "    <th>0.279502</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('austen_fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/austen_fine.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2e5a87db738d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'austen_fine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name, device, strict, with_opt)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m\"Load model and optimizer state (if `with_opt`) `name` from `self.model_dir` using `device`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'{name}.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/austen_fine.pth'"
     ]
    }
   ],
   "source": [
    "learn.load('austen_fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"It is a truth\"\n",
    "NWORDS = 120\n",
    "NSENTENCES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a truth of his own . xxmaj he is a handsome young man ; his figure is liberal ; his strong wonder ; his figure will turn back to address himself -- he explains the livery but possibly as a good figure nonsense ; which may not appear to their liberal effect -- but he is not comparatively handsome ; he thinks candour , is a mild talking charade , but can not attempt it -- a sensible man -- i shall do it exceedingly ; but perhaps new cottage is not there yet where , it is not very hundreds . xxmaj my turn is humility , and your vanity has nothing to blush between them within the best time of\n"
     ]
    }
   ],
   "source": [
    "#learn.predict('Now came the', 100, temperature=0.25, min_p=0.01)\n",
    "print(\"\\n\".join(learn.predict(TEXT, NWORDS, temperature=1.1) for _ in range(NSENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a truth of it , which is not xxmaj to be done . xxmaj the xxmaj thrush is a xxmaj mrs. xxmaj cole 's wedding - clothes . xxmaj we are all to go to xxmaj town , and we are all to xxmaj bath . xxmaj we are all the xxmaj children , and we are on the point of xxmaj lord and xxmaj lady xxmaj lesley . xxmaj we are not to be seen , xxmaj eloisa , xxmaj eloisa , that we are all handsome . xxmaj we shall be very lively , and we are all very kind and kind . xxmaj we are very kind and dull , and we are the xxmaj party of the xxmaj\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, NWORDS, temperature=0.5) for _ in range(NSENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
